{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hse_BERT_2.ipynb","provenance":[],"authorship_tag":"ABX9TyMwxwxCDO6M+ha0mNSt+cBJ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wFOv_GdndRBf"},"source":["# Подготовка среды"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RNIRbsjvXTT1","executionInfo":{"status":"ok","timestamp":1613971762890,"user_tz":-180,"elapsed":794,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}},"outputId":"a26188e1-654d-46f6-d7e8-1919deba87c2"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e3Jn3fsZ3oVD","executionInfo":{"status":"ok","timestamp":1613971768132,"user_tz":-180,"elapsed":799,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}}},"source":["import pickle as pc\r\n","import numpy as np\r\n","import numpy"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"SrMRUKMUZC-W","executionInfo":{"status":"ok","timestamp":1613971768481,"user_tz":-180,"elapsed":971,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}}},"source":["import os\r\n","os.chdir('/content/drive/Shared drives/hse_BERT/hse_Af_Tr_BERT')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"aXjr0XyrdpLz"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qrzflXz2wdQG"},"source":["!pip install razdel"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zSA0MOOMTPgk","executionInfo":{"status":"ok","timestamp":1613971774411,"user_tz":-180,"elapsed":6408,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}}},"source":["import torch\r\n","import nltk\r\n","import re\r\n","import json\r\n","import time\r\n","import numpy as np\r\n","from transformers import BertTokenizer, BertModel\r\n","\r\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\r\n","import logging\r\n","#logging.basicConfig(level=logging.INFO)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","% matplotlib inline\r\n","\r\n","from scipy.spatial.distance import cosine"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9ge0GhZA0zzE"},"source":["# read embeddings"]},{"cell_type":"code","metadata":{"id":"OJxSs8oa00QK","executionInfo":{"status":"ok","timestamp":1613971781736,"user_tz":-180,"elapsed":13129,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}}},"source":["files = os.listdir(\"./embeddings/sent2/bin\")\r\n","cut_files = []\r\n","for i in files:\r\n","    if i.split('.')[-1] == 'pic':\r\n","        cut_files.append(i)\r\n","# cut_files"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"f_kbzYi51sTW","executionInfo":{"status":"ok","timestamp":1613971781737,"user_tz":-180,"elapsed":12856,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}}},"source":["# i = \"1000_00024.pic\"\r\n","# for i in cut_files:\r\n","#     with open(\"./embeddings/sent1/bin/{}\".format(i), 'rb') as f:\r\n","#         data = pc.load(f)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hHu7WxpNH0Fe"},"source":["##get count"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pV-8Gucl1sZd","executionInfo":{"status":"ok","timestamp":1613973913636,"user_tz":-180,"elapsed":2144269,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}},"outputId":"494ef98c-6752-45fb-f909-2d118148c1bd"},"source":["%%time\r\n","from_files = {}\r\n","all_count = {}\r\n","\r\n","for name in cut_files:\r\n","    with open(\"./embeddings/sent2/bin/{}\".format(name), 'rb') as f:\r\n","        data = pc.load(f)\r\n","    for i in data.keys():\r\n","        if i not in all_count:\r\n","            all_count[i] = len(data[i])\r\n","            from_files[i] = [name]\r\n","        else:\r\n","            all_count[i] += len(data[i])\r\n","            from_files[i].append(name)\r\n","    # print(name)\r\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["CPU times: user 15min 43s, sys: 39.2 s, total: 16min 22s\n","Wall time: 35min 31s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QS6qXPsK1sc_"},"source":["out = list(zip(all_count.keys(), list(all_count.values())))\r\n","out.sort(key = lambda i: i[1], reverse=True)\r\n","out[:20]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_tMbqY5CFNH1","executionInfo":{"status":"ok","timestamp":1613973913642,"user_tz":-180,"elapsed":2142167,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}},"outputId":"dedf5540-89b5-45bd-8934-ff1daa916891"},"source":["all_count[\"москв\"]"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6459"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wvOtbW-6a4np","executionInfo":{"status":"ok","timestamp":1613973913644,"user_tz":-180,"elapsed":2141587,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}},"outputId":"d7366d2c-5b18-477f-87e6-c52c37905e21"},"source":["keys = list(all_count.keys())\r\n","k1 = []\r\n","k2 = []\r\n","k3 = []\r\n","kb = []\r\n","l = 0\r\n","for i in keys:\r\n","    l = len(i)\r\n","    if l == 1:\r\n","        k1.append(i)\r\n","    elif l == 2:\r\n","        k2.append(i)\r\n","    elif l == 3:\r\n","        k3.append(i)\r\n","    else:\r\n","        kb.append(i)\r\n","len(k1),len(k2),len(k3),len(kb)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0, 0, 2068, 52527)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIHeXRv2cbM6","executionInfo":{"status":"ok","timestamp":1613973913646,"user_tz":-180,"elapsed":2140924,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}},"outputId":"62b79fec-8601-4c72-ad81-24a60a3bb0b0"},"source":["all_words = []\r\n","for i in kb:\r\n","    if all_count[i] > 10:\r\n","        all_words.append(i)\r\n","len(all_words)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["37553"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"zzUkB5fhHbDt","executionInfo":{"status":"ok","timestamp":1613973913651,"user_tz":-180,"elapsed":2140150,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}}},"source":["def check_existing_emb(words):\r\n","    d = dict(out)\r\n","    fl = True\r\n","    for i in words:\r\n","        if i not in d:\r\n","            print(\"{} not in dictionary\".format(i))\r\n","            fl = False\r\n","    return fl\r\n","\r\n","def get_all_embeddingd(words):\r\n","    all_files = []\r\n","    embeddings = {}\r\n","    for w in words:\r\n","        embeddings[w] = []\r\n","\r\n","    for i in words:\r\n","        all_files += from_files[i]\r\n","\r\n","    for name in set(all_files):\r\n","        with open(\"./embeddings/sent2/bin/{}\".format(name), 'rb') as f:\r\n","            data = pc.load(f)\r\n","        for w in words:\r\n","            if w in data:\r\n","                embeddings[w] += data[w]\r\n","    return embeddings\r\n","\r\n","def sum_embeddings(embeddings):\r\n","    res = {}\r\n","    res_emb = {}\r\n","    for i in embeddings:\r\n","        res[i] = torch.empty(len(embeddings[i]), embeddings[i][0].size(0))\r\n","        for j in range(len(embeddings[i])):\r\n","            res[i][j] = embeddings[i][j]\r\n","        res_emb[i] = res[i].mean(dim = 0)\r\n","    return res_emb"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":493},"id":"IgRmaNBcBu_J","executionInfo":{"status":"error","timestamp":1614003386805,"user_tz":-180,"elapsed":9183213,"user":{"displayName":"Андрей Солодянкин","photoUrl":"","userId":"09767960549124606880"}},"outputId":"398762d3-8815-4815-e284-8bb35a436c66"},"source":["%%time\r\n","st_time = time.time()\r\n","all_emb = {}\r\n","batch = 1000\r\n","for b in range(3, len(all_words)//batch):\r\n","    t_time = time.time()\r\n","    words = all_words[b*batch+100:(b+1)*batch+100]\r\n","    emb = get_all_embeddingd(words)\r\n","    res_emb = sum_embeddings(emb)\r\n","    \r\n","    with open(\"./embeddings/sent2/ready/{}_{:05d}.pic\".format(batch, b), 'wb') as f:\r\n","        pc.dump(res_emb, f)\r\n","\r\n","    print(\"done: {} --- time: {}\\t--- total: {}\".format(b,time.time() - t_time, time.time() - st_time))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["done: 3 --- time: 2030.1835765838623\t--- total: 2030.1835877895355\n","done: 4 --- time: 2001.3426187038422\t--- total: 4031.530666589737\n","done: 5 --- time: 2104.9691150188446\t--- total: 6136.507919788361\n","done: 6 --- time: 2191.766023159027\t--- total: 8328.278025627136\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-4b7a3761fb62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'st_time = time.time()\\nall_emb = {}\\nbatch = 1000\\nfor b in range(3, len(all_words)//batch):\\n    t_time = time.time()\\n    words = all_words[b*batch+100:(b+1)*batch+100]\\n    emb = get_all_embeddingd(words)\\n    res_emb = sum_embeddings(emb)\\n    \\n    with open(\"./embeddings/sent2/ready/{}_{:05d}.pic\".format(batch, b), \\'wb\\') as f:\\n        pc.dump(res_emb, f)\\n\\n    print(\"done: {} --- time: {}\\\\t--- total: {}\".format(b,time.time() - t_time, time.time() - st_time))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m<ipython-input-20-64cc730cfbb2>\u001b[0m in \u001b[0;36mget_all_embeddingd\u001b[0;34m(words)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./embeddings/sent2/bin/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/storage.py\u001b[0m in \u001b[0;36m_load_from_bytes\u001b[0;34m(b)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_load_from_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"qgbWPFkV8Ctt"},"source":["words"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3F7kbbmrH4sT"},"source":["## get embeddings"]},{"cell_type":"code","metadata":{"id":"z5KEphwROsy_"},"source":["%%time\r\n","# words = ['мать', 'сын', 'отец', 'дочь', 'парень', 'девушка', 'машина', 'автомобиль', 'самолет', 'ребенок', 'королева', 'король', 'лед', 'тепло', 'вода']\r\n","words = ['россия','москв','франци','париж','украин','киев']\r\n","\r\n","if check_existing_emb(words):\r\n","    emb = get_all_embeddingd(words)\r\n","    res_emb = sum_embeddings(emb)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3xwUIz_vUNsm"},"source":["t1 = res_emb['франци'] - res_emb['париж'] + res_emb['киев']\r\n","t2 = res_emb['украин']\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fuB9zah9UN9F"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o2ipTLE-UOCG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MMcKl9gPRkjY"},"source":["mother = res_emb['мать']\r\n","father = res_emb['отец']\r\n","sun = res_emb['сын']\r\n","dot = res_emb['дочь']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTA0HYGB-h_Y"},"source":["t1 = res_emb['девушка'] - res_emb['парень'] + res_emb['сын']\r\n","t2 = res_emb['дочь']\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uElQlw28IbbD"},"source":["t1 = res_emb['король'] - res_emb['парень'] + res_emb['девушка']\r\n","t2 = res_emb['королева']\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Y2OMQFcIvtb"},"source":["t1 = res_emb['король'] - res_emb['королева']\r\n","t2 = res_emb['девушка'] - res_emb['парень']\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kH7PgjWtB9eY"},"source":["t1 = res_emb['отец'] - res_emb['парень'] + res_emb['девушка']\r\n","t2 = res_emb['мать']\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SSwhPJm-nqL"},"source":["t1 = res_emb['девушка']\r\n","t2 = res_emb['автомобиль']\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2PrvWbb7B3HC"},"source":["t1 = res_emb['машина']\r\n","t2 = res_emb['автомобиль']\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qnurMtwbUy78"},"source":["t1 = mother - father + sun\r\n","t2 = dot\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OzR_wCkPUzAn"},"source":["t1 = mother\r\n","t2 = dot\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ot_kYH5cUzDh"},"source":["t1 = father\r\n","t2 = sun\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DJuzMl3UzGy"},"source":["t1 = sun\r\n","t2 = dot\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"trqPoVJbUzJo"},"source":["t1 = mother\r\n","t2 = father\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0lZ3FMjEcUP4"},"source":["t1 = mother\r\n","t2 = sun\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F_mmvAJ1cUT7"},"source":["t1 = father\r\n","t2 = dot\r\n","diff_bank = 1 - cosine(t1, t2)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hTzf59SKXjex"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iJ1Jbokqml8X"},"source":["# short "]},{"cell_type":"markdown","metadata":{"id":"mSnTVO95wEqL"},"source":["## imports"]},{"cell_type":"code","metadata":{"id":"iCBwhjwymmux"},"source":["import torch\r\n","import nltk\r\n","from transformers import BertTokenizer, BertModel\r\n","\r\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\r\n","import logging\r\n","#logging.basicConfig(level=logging.INFO)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","% matplotlib inline\r\n","\r\n","from scipy.spatial.distance import cosine\r\n","\r\n","# Load pre-trained model tokenizer (vocabulary)\r\n","tokenizer = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eiaAhMe7nU6N"},"source":["# Load pre-trained model (weights)\r\n","model = BertModel.from_pretrained('DeepPavlov/rubert-base-cased',\r\n","                                  output_hidden_states = True, # Whether the model returns all hidden-states.\r\n","                                  )\r\n","# Put the model in \"evaluation\" mode, meaning feed-forward operation.\r\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t0SKv0m8warN"},"source":["from razdel import sentenize\r\n","# list(sentenize(text))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n98R8rEWxSOJ"},"source":["\r\n","nltk.download('punkt')\r\n","nltk.download('averaged_perceptron_tagger')\r\n","# sentence = \"\"\"At eight o'clock on Thursday morning. Arthur didn't feel very good.\"\"\"\r\n","tokens = nltk.word_tokenize(sentences[1])\r\n","tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lj1Lu9WPyRk1"},"source":["sentences = nltk.sent_tokenize(text)\r\n","sentences"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MqaOLbQ3xb1V"},"source":["tagged = nltk.pos_tag(tokens)\r\n","tagged[0:6]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ADtaVlDjwH9p"},"source":["## work"]},{"cell_type":"code","metadata":{"id":"A_5phDHumt1i"},"source":["text = 'Замок стоял неприступный. Замок легко открылся.'\r\n","text2 = \"At eight o'clock on Thursday morning. Arthur didn't feel very good.\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q2BCGpfIeO1G"},"source":["# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\r\n","\r\n","# marked_text2 = \"[CLS] \" + \"Работает по следующему принципу\" + \" [SEP]\"\r\n","# tokenized_text2 = tokenizer.tokenize(marked_text2)\r\n","# tokenized_text2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E1TawqaTmt5A"},"source":["marked_text2 = text.lower()\r\n","marked_text = \"[CLS] \" + text + \" [SEP]\"\r\n","\r\n","tokenized_text = tokenizer.tokenize(marked_text)\r\n","# tokenized_text = nltk.word_tokenize(marked_text)\r\n","\r\n","# tokenized_text = [\"[CLS]\"] + tokenized_text + [\"[SEP]\"]\r\n","\r\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\r\n","segments_ids = [1] * len(tokenized_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKlj14WFaL6V"},"source":["tokenized_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wPr8IKKmt_3"},"source":["# Convert inputs to PyTorch tensors\r\n","tokens_tensor = torch.tensor([indexed_tokens])\r\n","segments_tensors = torch.tensor([segments_ids])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-f0yAQrsnigF"},"source":["with torch.no_grad():\r\n","    outputs = model(tokens_tensor, segments_tensors)\r\n","    hidden_states = outputs[2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qQOs50kOnisy"},"source":["# token_i = 5\r\n","# layer_i = 5\r\n","# vec = hidden_states[layer_i][batch_i][token_i]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PfKPm4a2gMRc"},"source":["# For the 5th token in our sentence, select its feature values from layer 5.\r\n","token_i = 5\r\n","layer_i = 5\r\n","vec = hidden_states[layer_i][batch_i][token_i]\r\n","\r\n","# Plot the values as a histogram to show their distribution.\r\n","plt.figure(figsize=(10,10))\r\n","plt.hist(vec, bins=200)\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PFmJdLgJnui8"},"source":["# Remove dimension 1, the \"batches\".\r\n","token_embeddings = torch.stack(hidden_states, dim=0)\r\n","token_embeddings = torch.squeeze(token_embeddings, dim=1).permute(1,0,2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gh65R4Mun7dX"},"source":["token_vecs_sum = []\r\n","for token in token_embeddings:\r\n","    sum_vec = torch.sum(token[-4:], dim=0)\r\n","    token_vecs_sum.append(sum_vec)\r\n","\r\n","print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u5b6OwZDqqhR"},"source":["len(token_vecs_sum)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Za7aF1iQrYJE"},"source":["for i, token_str in enumerate(tokenized_text):\r\n","  print (i, token_str)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ThBR9wTfoA4k"},"source":["token_vecs = hidden_states[-2][0]\r\n","sentence_embedding = torch.mean(token_vecs, dim=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PEjdLKPEbm2J"},"source":["token_vecs.size()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KfHWSz36oA78"},"source":["diff_bank = 1 - cosine(token_vecs_sum[1], token_vecs_sum[7])\r\n","diff_bank1 = 1 - cosine(token_vecs[1], token_vecs[7])\r\n","# same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\r\n","\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank)\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % diff_bank1)\r\n","# print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dXtCWy7idfs5"},"source":["# Baseline\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"1vz_xfmsdqX_"},"source":["import torch\r\n","from transformers import BertTokenizer, BertModel\r\n","\r\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\r\n","import logging\r\n","#logging.basicConfig(level=logging.INFO)\r\n","\r\n","import matplotlib.pyplot as plt\r\n","% matplotlib inline\r\n","\r\n","# Load pre-trained model tokenizer (vocabulary)\r\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CaU-dkwpdyar"},"source":["text = \"Here is the sentence I want embeddings for.\"\r\n","marked_text = \"[CLS] \" + text + \" [SEP]\"\r\n","\r\n","# Tokenize our sentence with the BERT tokenizer.\r\n","tokenized_text = tokenizer.tokenize(marked_text)\r\n","\r\n","# Print out the tokens.\r\n","print (tokenized_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NDdQ7uDRd5R4"},"source":["# Define a new example sentence with multiple meanings of the word \"bank\"\r\n","text = \"After stealing money from the bank vault, the bank robber was seen \" \\\r\n","       \"fishing on the Mississippi river bank.\"\r\n","\r\n","# Add the special tokens.\r\n","marked_text = \"[CLS] \" + text + \" [SEP]\"\r\n","\r\n","# Split the sentence into tokens.\r\n","tokenized_text = tokenizer.tokenize(marked_text)\r\n","\r\n","# Map the token strings to their vocabulary indeces.\r\n","indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\r\n","\r\n","# Display the words with their indeces.\r\n","for tup in zip(tokenized_text, indexed_tokens):\r\n","    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6sQM8BeAeP0Z"},"source":["# Mark each of the 22 tokens as belonging to sentence \"1\".\r\n","segments_ids = [1] * len(tokenized_text)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AcZ2TlS6eCHo"},"source":["# Convert inputs to PyTorch tensors\r\n","tokens_tensor = torch.tensor([indexed_tokens])\r\n","segments_tensors = torch.tensor([segments_ids])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7fWcVbNNeMHa"},"source":["# Load pre-trained model (weights)\r\n","model = BertModel.from_pretrained('bert-base-uncased',\r\n","                                  output_hidden_states = True, # Whether the model returns all hidden-states.\r\n","                                  )\r\n","\r\n","# Put the model in \"evaluation\" mode, meaning feed-forward operation.\r\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tp_jYk_5eUB3"},"source":["# Run the text through BERT, and collect all of the hidden states produced\r\n","# from all 12 layers. \r\n","with torch.no_grad():\r\n","\r\n","    outputs = model(tokens_tensor, segments_tensors)\r\n","\r\n","    # Evaluating the model will return a different number of objects based on \r\n","    # how it's  configured in the `from_pretrained` call earlier. In this case, \r\n","    # becase we set `output_hidden_states = True`, the third item will be the \r\n","    # hidden states from all layers. See the documentation for more details:\r\n","    # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\r\n","    hidden_states = outputs[2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOImPmmufFeO"},"source":["# outputs.shape\r\n","hidden_states"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlk64upJfIP4"},"source":["print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")\r\n","layer_i = 0\r\n","\r\n","print (\"Number of batches:\", len(hidden_states[layer_i]))\r\n","batch_i = 0\r\n","\r\n","print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i]))\r\n","token_i = 0\r\n","\r\n","print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TYDKqBYNhOGZ"},"source":["# For the 5th token in our sentence, select its feature values from layer 5.\r\n","token_i = 5\r\n","layer_i = 5\r\n","vec = hidden_states[layer_i][batch_i][token_i]\r\n","\r\n","# Plot the values as a histogram to show their distribution.\r\n","plt.figure(figsize=(10,10))\r\n","plt.hist(vec, bins=200)\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oD82_lhOky7g"},"source":["# Remove dimension 1, the \"batches\".\r\n","\r\n","token_embeddings = torch.stack(hidden_states, dim=0)\r\n","token_embeddings = torch.squeeze(token_embeddings, dim=1)\r\n","\r\n","token_embeddings.size()\r\n","\r\n","# Swap dimensions 0 and 1.\r\n","token_embeddings = token_embeddings.permute(1,0,2)\r\n","\r\n","token_embeddings.size()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3UT-Pbq7hhzV"},"source":["# Stores the token vectors, with shape [22 x 3,072]\r\n","token_vecs_cat = []\r\n","\r\n","# `token_embeddings` is a [22 x 12 x 768] tensor.\r\n","\r\n","# For each token in the sentence...\r\n","for token in token_embeddings:\r\n","    \r\n","    # `token` is a [12 x 768] tensor\r\n","\r\n","    # Concatenate the vectors (that is, append them together) from the last \r\n","    # four layers.\r\n","    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\r\n","    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\r\n","    \r\n","    # Use `cat_vec` to represent `token`.\r\n","    token_vecs_cat.append(cat_vec)\r\n","\r\n","print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U2mSMHsghUkx"},"source":["# Stores the token vectors, with shape [22 x 768]\r\n","token_vecs_sum = []\r\n","\r\n","# `token_embeddings` is a [22 x 12 x 768] tensor.\r\n","\r\n","# For each token in the sentence...\r\n","for token in token_embeddings:\r\n","\r\n","    # `token` is a [12 x 768] tensor\r\n","\r\n","    # Sum the vectors from the last four layers.\r\n","    sum_vec = torch.sum(token[-4:], dim=0)\r\n","    \r\n","    # Use `sum_vec` to represent `token`.\r\n","    token_vecs_sum.append(sum_vec)\r\n","\r\n","print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2ZHmxSFlNDt"},"source":["# `hidden_states` has shape [13 x 1 x 22 x 768]\r\n","\r\n","# `token_vecs` is a tensor with shape [22 x 768]\r\n","token_vecs = hidden_states[-2][0]\r\n","\r\n","# Calculate the average of all 22 token vectors.\r\n","sentence_embedding = torch.mean(token_vecs, dim=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JRdzQAmilRws"},"source":["from scipy.spatial.distance import cosine\r\n","\r\n","# Calculate the cosine similarity between the word bank \r\n","# in \"bank robber\" vs \"river bank\" (different meanings).\r\n","diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\r\n","\r\n","# Calculate the cosine similarity between the word bank\r\n","# in \"bank robber\" vs \"bank vault\" (same meaning).\r\n","same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\r\n","\r\n","print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\r\n","print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6sLrZsOclZSI"},"source":[""],"execution_count":null,"outputs":[]}]}